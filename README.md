# Elasticsearch + Databricks PoC

Esta prova de conceito demonstra como integrar **Elasticsearch** e **Databricks** para:

- Extrair logs indexados no Elasticsearch
- Enriquecer com PySpark (usando regras simples ou ML)
- Retornar os dados enriquecidos ao Elasticsearch
- Visualizar insights via Kibana

---

## ðŸ“Œ Objetivo

Unir a velocidade de busca do Elasticsearch com o poder de processamento do Databricks, criando uma arquitetura de observabilidade inteligente.

---

## ðŸ› ï¸ Passo a passo para executar a PoC

### ðŸ”¹ PrÃ©-requisitos
- Elasticsearch rodando localmente ou acessÃ­vel por IP
- Databricks Workspace ativo (com cluster Spark)
- Conector Elasticsearch para Spark instalado no cluster

---

### ðŸ” Etapas

 1. Criar o Ã­ndice no Elasticsearch
=======
#### 1. Criar o Ã­ndice no Elasticsearch
Execute via Kibana Dev Tools ou API:

```json
PUT logs-api
{
  "mappings": {
    "properties": {
      "timestamp": { "type": "date" },
      "level": { "type": "keyword" },
      "message": { "type": "text" },
      "service": { "type": "keyword" }
    }
  }
}

2. Ingerir os logs de exemplo

curl -X POST "http://localhost:9200/logs-api/_bulk" -H 'Content-Type: application/json' --data-binary @elastic/log-sample.json


3. No Databricks, execute os scripts na seguinte ordem:
(a) extract_elastic.py â€“ extrai os dados e salva em /tmp/logs_raw

(b) enrich_logs.py â€“ aplica regras e salva como /tmp/logs_enriched

(c) return_to_elastic.py â€“ envia os dados tratados ao Ã­ndice logs-enriched

Alternativamente, execute o notebook LogAnalysisDatabricks.ipynb que contÃ©m todas as etapas agrupadas.

4. Visualize os dados enriquecidos no Kibana
Crie index pattern: logs-enriched

Explore os campos, incluindo classificacao

=======
```

---

#### 2. Ingerir os logs de exemplo

```bash
curl -X POST "http://localhost:9200/logs-api/_bulk" -H 'Content-Type: application/json' --data-binary @elastic/log-sample.json
```

---

#### 3. No Databricks, execute os scripts na seguinte ordem:

(a) `extract_elastic.py` â€“ extrai os dados e salva em `/tmp/logs_raw`  
(b) `enrich_logs.py` â€“ aplica regras e salva como `/tmp/logs_enriched`  
(c) `return_to_elastic.py` â€“ envia os dados tratados ao Ã­ndice `logs-enriched`

> Alternativamente, execute o notebook `LogAnalysisDatabricks.ipynb` que contÃ©m todas as etapas agrupadas.

---

#### 4. Visualize os dados enriquecidos no Kibana

- Crie index pattern: `logs-enriched`
- Explore os campos, incluindo `classificacao`

---

## ðŸ“¦ Estrutura do Projeto

```
elasticsearch-databricks-poc/
â”œâ”€â”€ elastic/
â”‚   â”œâ”€â”€ log-sample.json
â”‚   â””â”€â”€ elastic-config.md
â”œâ”€â”€ databricks/
â”‚   â”œâ”€â”€ extract_elastic.py
â”‚   â”œâ”€â”€ enrich_logs.py
â”‚   â”œâ”€â”€ return_to_elastic.py
â”‚   â””â”€â”€ notebooks/
â”‚       â””â”€â”€ LogAnalysisDatabricks.ipynb
â”œâ”€â”€ data/enriched_sample.csv
â””â”€â”€ assets/architecture-diagram.png


=======
```

## ðŸ“Ž Links

- GitHub: [rafasilva1984](https://github.com/rafasilva1984)
- LinkedIn: [Rafael Silva](https://linkedin.com/in/rafael-silva-leader-coordenador)
- Medium: [rafaelldasilva](https://medium.com/@rafaelldasilva)

---

#Elasticsearch #Databricks #Observabilidade #DataOps #BigData #MachineLearning
